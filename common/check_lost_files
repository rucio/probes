#!/usr/bin/env python
# Copyright European Organization for Nuclear Research (CERN) 2015
#
# Licensed under the Apache License, Version 2.0 (the "License");
# You may not use this file except in compliance with the License.
# You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
#
# Authors:
# - Tomas Javurek, Cedric Serfon, 2015
# - Alexander Bogdanchikov, 2019

# the next block avoids security warnings of type
# InsecureRequestWarning: Unverified HTTPS request is being made.
# Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
import urllib3.contrib.pyopenssl
urllib3.contrib.pyopenssl.inject_into_urllib3()
import certifi
import urllib3
http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED', ca_certs=certifi.where())

import os
import sys
import smtplib
import time
import requests
import calendar
from email.mime.text import MIMEText
from email.MIMEMultipart import MIMEMultipart
from email.MIMEBase import MIMEBase
from email import Encoders
# from rucio.common.config import config_get
from datetime import datetime
from datetime import date

from rucio.db.sqla.session import get_session
# from rucio.core import monitor

# Exit statuses
OK, WARNING, CRITICAL, UNKNOWN = 0, 1, 2, 3

max_lines_inline = 30
users = True
groups = True
gdp = True

test_mode = True
force_rucio_select = False  # set it to True to force selection from rucio, even if rucio-hadoop request was successful
create_dirs = True

#tester_email = 'tomas.javurek@cern.ch'
tester_email = 'Alexander.Bogdanchikov@cern.ch'
#always_report_email = 'tomas.javurek@cern.ch'
always_report_email = 'Alexander.Bogdanchikov@cern.ch'
#gdp_emails = ['atlas-adc-dpa@cern.ch', 'tomas.javurek@cern.ch']
gdp_emails = ['agbogdan@cern.ch']
from_email = 'atlas-adc-ddm-support@cern.ch'

# run script on working_days only
working_days = ['Wednesday']

timestamp = datetime.today().strftime('%Y-%m-%d')

#log_dir = '/var/log/rucio/lost_files/logs'
if not test_mode:
    base_dir = '/var/log/rucio/lost_files'
else:
    base_dir = '/afs/cern.ch/user/a/agbogdan/lost_files'

log_dir = base_dir + '/logs'
tmp_dir = base_dir + '/tmp'
reports_dir = base_dir + '/reports'

tmpdata_path = tmp_dir + '/rse-lost-files.txt'
tmpdata_path2 = tmp_dir + '/rse-lost-files2.txt'
log_path = log_dir + "/" + timestamp + '.log'

def dirs_exist(dirs, create_if_not_exist = False):
    """
    checks the existence of directories and create them if not exist
    :param dirs: list of directories, check starts from the beginning of the list
    :param create_if_not_exist: flag to create directories if not exists
    :return: True on success, False otherwise
    """
    for check_dir in dirs:
        if not os.path.isdir(check_dir):
            if os.path.exists(check_dir):
                if test_mode:
                    print ('DEBUG: failure: %s exists but not a directory ' % check_dir)
                return False
            if create_if_not_exist:
                try:
                    if test_mode:
                        print ('DEBUG: mkdir missed directory %s' % check_dir)
                    os.mkdir(check_dir, 0755)
                    continue
                except OSError as err:
                    if test_mode:
                        print ('DEBUG: failed to mkdir missed directory %s: %s' % (check_dir, err))
                    return False
            else:
                if test_mode:
                    print ('DEBUG: failure: directory %s is missed, flag create_if_not_existis is %s ' % (check_dir, create_if_not_exist))
                return False
    return True


# protection against running this script every day
def run_judger(run_days):

    today = calendar.day_name[date.today().weekday()]
    flog = open(log_path, 'a')
    if today in run_days:
        flog.write('Today is %s.\n' % today)
        flog.write('I might try to work today.\n')
        return True
    else:
        flog.write('Today is %s. This is NOT my working day! I am working only on:\n' % today)
        flog.write(str(run_days) + '\n')
        return False


def merge_dicts(d1, d2):

    dm = d1.copy()
    for a in d2.keys():
        if a not in dm.keys():
            dm[a] = d2[a]
        else:
            dm[a] = list(set(dm[a] + d2[a]))
    return dm


# extracting mails of users from Rucio DB
def find_mails_users(account, session):

    mails = []
    try:
        query = ''' select distinct a.email from atlas_rucio.identities a, atlas_rucio.account_map b where
a.identity=b.identity and b.account='%s'  ''' % account
        result = session.execute(query)
        for row in result:
            for col in row:
                mails.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('find_mails_users\n')
        flog.write(str(e) + '\n')
        sys.exit(CRITICAL)
    if account == 'ddmadmin' or account == 'root':
        mails = ['atlas-adc-ddm-support@cern.ch']
    if always_report_email not in mails:
        mails.append(always_report_email)

    return mails


# hardcoded, TODO
def find_mails_gdp():
    return gdp_emails

# extracting mails of physgroups from Rucio DB
def find_mails_groups(rse, session):
    """
    :param rse:
    :param session:
    :return:
    """
    mails = []
    try:
        query = ''' select distinct email from atlas_rucio.identities where identity in
 (select identity from atlas_rucio.account_map where account in
 (select value from atlas_rucio.rse_attr_map where key = 'physgroup' and rse_id = atlas_rucio.rse2id('%s'))) ''' % rse
        result = session.execute(query)
        for row in result:
            for col in row:
                mails.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('find_mails_groups\n')
        flog.write(str(e) + '\n')
        sys.exit(CRITICAL)

    if always_report_email not in mails:
        mails.append(always_report_email)

    return mails


# find account for rule on given did
def get_rule_owners(scope, name, session):

    rule_owners = []
    try:
        query = ''' select distinct(account) from atlas_rucio.rules where scope='%s' and name='%s'  ''' % (scope, name)
        result = session.execute(query)
        for row in result:
            for col in row:
                rule_owners.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('get_rule_owners:')
        flog.write(str(e) + '\n')

    if test_mode:
        print 'DEBUG: ', scope, name
        print 'DEBUG: rule owners', rule_owners

    return rule_owners


# collects reports for given email
def report_collector(rse, account, session):

    if test_mode:
        print ("DEBUG: report_collector was called with (%s, %s, %s)" % (rse, account, session))
    mails_reports = {}
    mail_list = []
    report_path = ''
    if groups and rse != '':
        mail_list = find_mails_groups(rse, session)
        report_path = reports_dir + '/' + 'report_' + rse
    if users and account != '' and account != 'gdp':
        mail_list = find_mails_users(account, session)
        report_path = reports_dir + '/' + 'report_' + account
    if gdp and account == 'gdp':
        mail_list = find_mails_gdp()
        report_path = reports_dir + '/' + 'report_' + account
    if mail_list == [] or report_path == '' or report_path == 'report_':
        return

    if test_mode:
        print ("DEBUG: report_collector created mail_list=%s" % mail_list)

    for mail in mail_list:
        if mail not in mails_reports:
            mails_reports[mail] = [report_path]
        else:
            mails_reports[mail].append(report_path)

    if test_mode:
        print ("DEBUG: report_collector created mail_reports=%s" % mails_reports)

    return mails_reports


# mailing agent
def send_report(to_mail, report_paths):

    if test_mode:
        #print "DEBUG: mailing agent is accessed."
        print ("DEBUG: was called: send_report (to_mail=%s, report_paths=%s) " % (to_mail, report_paths))

    # defining mailing list
    if test_mode:
        print 'DEBUG: notification would be send to:', to_mail
        recipients = [tester_email]
    else:
        recipients = [to_mail]

    msg = MIMEMultipart()
    msg['Subject'] = 'DDMops: completely lost files that may affect you - last 7 days'
    msg['From'] = from_email
    msg['To'] = ", ".join(recipients)

    # email body
    msg.attach(MIMEText('Please check the attached list of files that have been lost and can not be recovered. These files may affect you. In case of questions contact DDMops.' + "\n\n"))

    # if report is short,lost files are reported in email body as well
    lines = []
    for report_path in report_paths:
        fr = open(report_path, 'r')
        for lost_file in fr.readlines():
            lines.append(lost_file)
        fr.close()
        if len(lines) > max_lines_inline:
            lines.append('... (see the full list in attachment!)')
            break


    #if len(lines) <= max_lines_inline:
    for l in lines:
        msg.attach(MIMEText(str(l)))

    # attachments
    for report_path in report_paths:
        fr = open(report_path, 'rb')
        part = MIMEBase('text', 'plain')
        part.set_payload(fr.read())
        Encoders.encode_base64(part)
        part.add_header('Content-Disposition', 'attachment; filename="%s"' % report_path)
        msg.attach(part)

    # sending email, s=server
    s = smtplib.SMTP('localhost')
    s.sendmail(from_email, recipients, msg.as_string())
    s.quit()

    flog = open(log_path, 'a')
    flog.write('Reports were sent to:\n')
    flog.write(str(recipients))
    if (recipients != [to_mail]):
        flog.write(" - for test, would be: " + to_mail )
    flog.write(str(report_paths))
    flog.write('\n\n')


# create report for gdp
# call mailing agent
def report_gdp():
    # INIT
    if test_mode:
        print "DEBUG: making report for GDP"
        print "||||||||||||||||||||||||||||"
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)

    cmd = 'cp %s %s' % (tmpdata_path, reports_dir + '/' + 'report_gdp')
    os.system(cmd)

    return ['gdp']


# make report by user
# call the mailing agent
def report_by_account(session):
    # INIT
    if test_mode:
        print "DEBUG: making report by account"
        print "|||||||||||||||||||||||||||||||"
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)
    fi = open(tmpdata_path, 'r')
    data_per_account = {}
    accs = []

    # loop over lost files from get_bad_files()
    for line in fi.readlines():
        scope = line.split(' ')[0]
        data_name = line.split(' ')[1]
        dataset = line.split(' ')[3]
        rse_name = line.split(' ')[4]
        account = line.split(' ')[5]
        updated_at = line.split(' ')[6]
        accounts = []

        # find owners of rule, they are contacted as well
        if test_mode:
            print "DEBUG: get rule owners"
        rule_owners = get_rule_owners(scope, dataset, session)
        # did_woners = get_did_owner TO BE DEVELOPED
        for own in rule_owners:
            if own not in accounts:
                accounts.append(own)
        if test_mode:
            print 'INFO:', rse_name, account, dataset, data_name
            if accounts == []:
                print "DEBUG: there is no account to be notified."
            else:
                print "DEBUG: rule owners found:", accounts
            print '======================='

        for acc in accounts:
            if acc not in data_per_account.keys():
                data_per_account[acc] = [{'scope': scope, 'name': data_name, 'dataset': dataset, 'rse': rse_name, 'time': updated_at}]
            else:
                data_per_account[acc].append({'scope': scope, 'name': data_name, 'dataset': dataset, 'rse': rse_name, 'time': updated_at})

    if test_mode:
        print "DEBUG: creating reports and sending."

    # create report per account
    for account in data_per_account.keys():
        fo = open(reports_dir + '/' + 'report_' + account, 'w')
        for bad_file in data_per_account[account]:
            fo.write("%s %s %s %s\n" % (bad_file['scope'], bad_file['dataset'], bad_file['name'], bad_file['time']))

    # send report by mail
    for account in data_per_account.keys():
        if test_mode:
            print "DEBUG: going to send the report."
        accs.append(account)

    if test_mode:
        if data_per_account == {}:
            print "DEBUG: nothing to send."

    if test_mode:
        print "DEBUG: report by accnounts done."
    fi.close()
    return accs


# make report for each rse
# call the mailing agent
def report_by_rses(session):

    rses = []
    # INIT
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)
    fi = open(tmpdata_path, 'r')
    data_per_rse = {}

    # loop over lost files from get_bad_files()
    for line in fi.readlines():
        scope = line.split(' ')[0]
        data_name = line.split(' ')[1]
        dataset = line.split(' ')[3]
        rse_name = line.split(' ')[4]
        account = line.split(' ')[5]
        updated_at = line.split(' ')[6]

        if rse_name not in data_per_rse.keys():
            data_per_rse[rse_name] = [{'scope': scope, 'name': data_name, 'dataset': dataset, 'account': account, 'time': updated_at, 'rse': rse_name}]
        else:
            data_per_rse[rse_name].append({'scope': scope, 'name': data_name, 'dataset': dataset, 'account': account, 'time': updated_at, 'rse': rse_name})

    # create report per rse
    for rse in data_per_rse.keys():
        fo = open(reports_dir + '/' + 'report_' + rse, 'w')
        for bad_file in data_per_rse[rse]:
            fo.write("%s %s %s %s\n" % (bad_file['scope'], bad_file['dataset'], bad_file['name'], bad_file['time']))

    # send report by mail
    for rse in data_per_rse.keys():
        rses.append(rse)

    fi.close()
    return rses


# the input
def get_bad_files(session, outfile=tmpdata_path):

    f = open(outfile, 'w')
    try:
        query = ''' select a.scope, a.name, b.scope, b.name, atlas_rucio.id2rse(a.rse_id), a.account, a.updated_at from atlas_rucio.bad_replicas a, atlas_rucio.contents_history b
 where a.state='L' and a.updated_at>sysdate-7 and b.did_type='D'and a.scope=b.child_scope and a.name=b.child_name '''

        result = session.execute(query)
        processed_files = []
        for row in result:
            if row[3].startswith('panda.'):
                continue
            if '_sub' in row[3]:
                continue
            f_did = row[0] + ':' + row[1]
            if f_did in processed_files:
                print 'double counted:', f_did
                continue
            else:
                processed_files.append(f_did)
            for col in row:
                f.write('%s ' % col)
            f.write('\n')

    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('get_bad_files\n')
        flog.write(str(e) + "\n")
        return False

    return True


def get_bad_files_from_dump(session):

    flog = open(log_path, 'a')
    url = 'https://rucio-hadoop.cern.ch/lost_files'
    #dump7 = requests.get(url, verify=True) # was verify=False)
    dump7 = http.request("GET", url)
    if dump7.status_code == 404:
        flog.write('ERROR: dump of bad files not reachable on hadoop')
        return False

    f = open(tmpdata_path, 'w')
    line_counter = 0
    processed_files = []
    for l in dump7.text.split('\n'):
        line_counter += 1
        data = l.split('\t')
        if len(data) < 7:
            flog.write('WARNING: line %i in dump does not contain full info \n' % line_counter)
            continue
        if data[3].startswith('panda.'):
            continue
        if '_sub' in data[3]:
            continue
        f_did = data[0] + ':' + data[1]
        if f_did in processed_files:
            print 'double counted:', f_did
            continue
        else:
            processed_files.append(f_did)
        updated_at = time.strftime('%Y-%m-%d', time.localtime(float(data[6])))
        f.write('%s %s %s %s %s %s %s\n' % (data[0], data[1], data[2], data[3], data[4], data[5], updated_at))
    flog.write('INFO: dump contains %i lines\n' % line_counter)

    return True


def main():

    # check folder hierarchy
    if not dirs_exist([base_dir, log_dir, tmp_dir, reports_dir], create_if_not_exist=create_dirs):
        sys.exit(CRITICAL)

    run_flag = run_judger(working_days)
    if not run_flag:
        sys.exit(OK)

    session = get_session()

    mails = {}
    # get input
    get_input = get_bad_files_from_dump(session)
    if not get_input:
        print 'WARNING: the dump is not accessible'
        get_input = get_bad_files(session)
        if not get_input:
            sys.exit(CRITICAL)
    elif force_rucio_select:
        print 'WARNING: forced rucio select flag is on, so call rucio'
        get_input = get_bad_files(session, outfile=tmpdata_path2)
        if not get_input:
            sys.exit(CRITICAL)

    # make and sent report to groups
    if groups:
        l_rses = report_by_rses(session)
        for rse in l_rses:
            reps = report_collector(rse, '', session)
            mails = merge_dicts(mails, reps)
    # make and sent report to users
    if users:
        l_acc = report_by_account(session)
        for acc in l_acc:
            reps = report_collector('', acc, session)
            mails = merge_dicts(mails, reps)
    if gdp:
        if test_mode:
            print "DEBUG: summary report to gdp"
        l_acc = report_gdp()
        for acc in l_acc:
            reps = report_collector('', acc, session)
            mails = merge_dicts(mails, reps)

    if len(list(set(mails.keys()))) != len(mails.keys()):
        print "ERROR: list of emails is not distinct"
        sys.exit('ERROR: list of emails is not distinct')

    if test_mode:
        send_report(tester_email, mails[tester_email])
        for m in mails.keys():
            flog = open(log_path, 'a')
            flog.write(m)
            flog.write(str(mails[m]))
            flog.write('\n')
    else:
        for m in mails.keys():
            send_report(m, mails[m])

    # clean tmp
    cmd = 'rm ' + tmpdata_path
    #os.system(cmd)

    sys.exit(OK)


if __name__ == '__main__':

    main()
