#!/usr/bin/env python
# Copyright European Organization for Nuclear Research (CERN) 2015
#
# Licensed under the Apache License, Version 2.0 (the "License");
# You may not use this file except in compliance with the License.
# You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
#
# Authors:
# - Tomas Javurek, Cedric Serfon, 2015
# - Alexander Bogdanchikov, 2019

import os
import sys
import smtplib
import time
import requests
import calendar
from email.mime.text import MIMEText
from email.MIMEMultipart import MIMEMultipart
from email.MIMEBase import MIMEBase
from email import Encoders
# from rucio.common.config import config_get
from datetime import datetime
from datetime import date

from rucio.db.sqla.session import get_session
# from rucio.core import monitor

# Exit statuses
OK, WARNING, CRITICAL, UNKNOWN = 0, 1, 2, 3

max_lines_inline = 30
users = True
groups = True
gdp = True

test_mode = True
force_to_work_any_day = True # if True and test_mode=True, force to run any day
force_rucio_select = False  # set it to True to force selection from rucio, even if rucio-hadoop request was successful
create_dirs = True

#tester_email = 'tomas.javurek@cern.ch'
tester_email = 'Alexander.Bogdanchikov@cern.ch'
#always_report_email = 'tomas.javurek@cern.ch'
always_report_email = 'Alexander.Bogdanchikov@cern.ch'
#gdp_emails = ['atlas-adc-dpa@cern.ch', 'tomas.javurek@cern.ch']
gdp_emails = ['agbogdan@cern.ch']
from_email = 'atlas-adc-ddm-support@cern.ch'

# run script on working_days only
working_days = ['Wednesday']

timestamp = datetime.today().strftime('%Y-%m-%d')

#log_dir = '/var/log/rucio/lost_files/logs'
if not test_mode:
    base_dir = '/var/log/rucio/lost_files'
else:
    base_dir = '/afs/cern.ch/user/a/agbogdan/lost_files'

log_dir = base_dir + '/logs'
tmp_dir = base_dir + '/tmp'
reports_dir = base_dir + '/reports'

tmpdata_path = tmp_dir + '/rse-lost-files.txt'
tmpdata_path2 = tmp_dir + '/rse-lost-files2.txt'
log_path = log_dir + "/" + timestamp + '.log'

def dirs_exist(dirs, create_if_not_exist = False):
    """
    checks the existence of directories and create them if not exist
    :param dirs: list of directories. Check starts from the beginning of the list
    :param create_if_not_exist: flag to create directories if not exists
    :return: True on success, False otherwise
    """
    for check_dir in dirs:
        if not os.path.isdir(check_dir):
            if os.path.exists(check_dir):
                if test_mode:
                    print ('DEBUG: failure: %s exists but not a directory ' % check_dir)
                return False
            if create_if_not_exist:
                try:
                    if test_mode:
                        print ('DEBUG: mkdir missed directory %s' % check_dir)
                    os.mkdir(check_dir, 0755)
                    continue
                except OSError as err:
                    if test_mode:
                        print ('DEBUG: failed to mkdir missed directory %s: %s' % (check_dir, err))
                    return False
            else:
                if test_mode:
                    print ('DEBUG: failure: directory %s is missed, flag create_if_not_existis is %s ' % (check_dir, create_if_not_exist))
                return False
    return True


# protection against running this script every day
def run_judger(run_days):
    """
    judge if the script has to run today according to run_days + allow run if force_to_work_day and test_mode flags are set
    :param run_days: list of days to run
    :return:  True if script can run
    """
    today = calendar.day_name[date.today().weekday()]
    flog = open(log_path, 'a')
    if today in run_days:
        flog.write('Today is %s.\n' % today)
        flog.write('I might try to work today.\n')
        return True
    else:
        flog.write('Today is %s. This is NOT my working day! I am working only on:\n' % today)
        flog.write("My run days are: " + run_days + '\n')
        if test_mode and force_to_work_any_day:
            print (
                    "INFO: I do not run on %s. Now I run because test_mode and force_to_work_any_day flags are set\n"
                    % today
            )
            flog.write("The test_mode and force_to_work_any_day flags are set, I will run\n")
            return True
        return False


def merge_dicts(d1, d2):

    dm = d1.copy()
    for a in d2.keys():
        if a not in dm.keys():
            dm[a] = d2[a]
        else:
            dm[a] = list(set(dm[a] + d2[a]))
    return dm


# extracting mails of users from Rucio DB
def find_mails_users(account, session):

    mails = []
    try:
        query = ''' select distinct a.email from atlas_rucio.identities a, atlas_rucio.account_map b where
a.identity=b.identity and b.account='%s'  ''' % account
        result = session.execute(query)
        for row in result:
            for col in row:
                mails.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('find_mails_users\n')
        flog.write(str(e) + '\n')
        sys.exit(CRITICAL)
    if account == 'ddmadmin' or account == 'root':
        mails = ['atlas-adc-ddm-support@cern.ch']
    if always_report_email not in mails:
        mails.append(always_report_email)

    return mails


# hardcoded, TODO
def find_mails_gdp():
    return gdp_emails

# extracting mails of physgroups from Rucio DB
def find_mails_groups(rse, session):
    """
    :param rse:
    :param session:
    :return:
    """
    mails = []
    try:
        query = ''' select distinct email from atlas_rucio.identities where identity in
 (select identity from atlas_rucio.account_map where account in
 (select value from atlas_rucio.rse_attr_map where key = 'physgroup' and rse_id = atlas_rucio.rse2id('%s'))) ''' % rse
        result = session.execute(query)
        for row in result:
            for col in row:
                mails.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('find_mails_groups\n')
        flog.write(str(e) + '\n')
        sys.exit(CRITICAL)

    if always_report_email not in mails:
        mails.append(always_report_email)

    return mails


# find account for rule on given did
def get_rule_owners(scope, name, session):

    rule_owners = []
    try:
        query = ''' select distinct(account) from atlas_rucio.rules where scope='%s' and name='%s'  ''' % (scope, name)
        result = session.execute(query)
        for row in result:
            for col in row:
                rule_owners.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('get_rule_owners:')
        flog.write(str(e) + '\n')

    if test_mode:
        print 'DEBUG: ', scope, name
        print 'DEBUG: rule owners', rule_owners

    return rule_owners


# collects reports for given email
def report_collector(rse, account, session):

    if test_mode:
        print ("DEBUG: report_collector was called with (%s, %s, %s)" % (rse, account, session))
    mails_reports = {}
    mail_list = []
    report_path = ''
    if groups and rse != '':
        mail_list = find_mails_groups(rse, session)
        report_path = reports_dir + '/' + 'report_' + rse
    if users and account != '' and account != 'gdp':
        mail_list = find_mails_users(account, session)
        report_path = reports_dir + '/' + 'report_' + account
    if gdp and account == 'gdp':
        mail_list = find_mails_gdp()
        report_path = reports_dir + '/' + 'report_' + account
    if mail_list == [] or report_path == '' or report_path == 'report_':
        return

    if test_mode:
        print ("DEBUG: report_collector created mail_list=%s" % mail_list)

    for mail in mail_list:
        if mail not in mails_reports:
            mails_reports[mail] = [report_path]
        else:
            mails_reports[mail].append(report_path)

    if test_mode:
        print ("DEBUG: report_collector created mail_reports=%s" % mails_reports)

    return mails_reports


# mailing agent
def send_report(to_mail, report_paths):

    if test_mode:
        #print "DEBUG: mailing agent is accessed."
        print ("DEBUG: was called: send_report (to_mail=%s, report_paths=%s) " % (to_mail, report_paths))

    # defining mailing list
    if test_mode:
        print 'DEBUG: notification would be send to:', to_mail
        recipients = [tester_email]
    else:
        recipients = [to_mail]

    msg = MIMEMultipart()
    msg['Subject'] = 'DDMops: completely lost files that may affect you - last 7 days'
    msg['From'] = from_email
    msg['To'] = ", ".join(recipients)

    # email body
    msg.attach(MIMEText('Please check the attached list of files that have been lost and can not be recovered. These files may affect you. In case of questions contact DDMops.' + "\n\n"))

    # if report is short,lost files are reported in email body as well
    lines = []
    for report_path in report_paths:
        fr = open(report_path, 'r')
        for lost_file in fr.readlines():
            lines.append(lost_file)
        fr.close()
        if len(lines) > max_lines_inline:
            lines.append('... (see the full list in attachment!)')
            break


    #if len(lines) <= max_lines_inline:
    for l in lines:
        msg.attach(MIMEText(str(l)))

    # attachments
    for report_path in report_paths:
        fr = open(report_path, 'rb')
        part = MIMEBase('text', 'plain')
        part.set_payload(fr.read())
        Encoders.encode_base64(part)
        part.add_header('Content-Disposition', 'attachment; filename="%s"' % report_path)
        msg.attach(part)

    # sending email, s=server
    s = smtplib.SMTP('localhost')
    s.sendmail(from_email, recipients, msg.as_string())
    s.quit()

    flog = open(log_path, 'a')
    flog.write('Reports were sent to:\n')
    flog.write(str(recipients))
    if (recipients != [to_mail]):
        flog.write(" - for test, would be: " + to_mail )
    flog.write(str(report_paths))
    flog.write('\n\n')


# create report for gdp
# call mailing agent
def report_gdp():
    # INIT
    if test_mode:
        print "DEBUG: making report for GDP"
        print "||||||||||||||||||||||||||||"
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)

    cmd = 'cp %s %s' % (tmpdata_path, reports_dir + '/' + 'report_gdp')
    os.system(cmd)

    return ['gdp']


# make report by user
# call the mailing agent
def report_by_account(session):
    # INIT
    if test_mode:
        print "DEBUG: making report by account"
        print "|||||||||||||||||||||||||||||||"
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)
    fi = open(tmpdata_path, 'r')
    data_per_account = {}
    accs = []

    # loop over lost files from get_bad_files()
    for line in fi.readlines():
        scope = line.split(' ')[0]
        data_name = line.split(' ')[1]
        dataset = line.split(' ')[3]
        rse_name = line.split(' ')[4]
        account = line.split(' ')[5]
        updated_at = line.split(' ')[6]
        accounts = []

        # find owners of rule, they are contacted as well
        if test_mode:
            print "DEBUG: get rule owners"
        rule_owners = get_rule_owners(scope, dataset, session)
        # did_woners = get_did_owner TO BE DEVELOPED
        for own in rule_owners:
            if own not in accounts:
                accounts.append(own)
        if test_mode:
            print 'INFO:', rse_name, account, dataset, data_name
            if accounts == []:
                print "DEBUG: there is no account to be notified."
            else:
                print "DEBUG: rule owners found:", accounts
            print '======================='

        for acc in accounts:
            if acc not in data_per_account.keys():
                data_per_account[acc] = [{'scope': scope, 'name': data_name, 'dataset': dataset, 'rse': rse_name, 'time': updated_at}]
            else:
                data_per_account[acc].append({'scope': scope, 'name': data_name, 'dataset': dataset, 'rse': rse_name, 'time': updated_at})

    if test_mode:
        print "DEBUG: creating reports and sending."

    # create report per account
    for account in data_per_account.keys():
        fo = open(reports_dir + '/' + 'report_' + account, 'w')
        for bad_file in data_per_account[account]:
            fo.write("%s %s %s %s\n" % (bad_file['scope'], bad_file['dataset'], bad_file['name'], bad_file['time']))

    # send report by mail
    for account in data_per_account.keys():
        if test_mode:
            print "DEBUG: going to send the report."
        accs.append(account)

    if test_mode:
        if data_per_account == {}:
            print "DEBUG: nothing to send."

    if test_mode:
        print "DEBUG: report by accounts done."
    fi.close()
    return accs


# make report for each rse
# call the mailing agent
def report_by_rses(session):

    rses = []
    # INIT
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)
    fi = open(tmpdata_path, 'r')
    data_per_rse = {}

    # loop over lost files from get_bad_files()
    for line in fi.readlines():
        scope = line.split(' ')[0]
        data_name = line.split(' ')[1]
        dataset = line.split(' ')[3]
        rse_name = line.split(' ')[4]
        account = line.split(' ')[5]
        updated_at = line.split(' ')[6]

        if rse_name not in data_per_rse.keys():
            data_per_rse[rse_name] = [{'scope': scope, 'name': data_name, 'dataset': dataset, 'account': account, 'time': updated_at, 'rse': rse_name}]
        else:
            data_per_rse[rse_name].append({'scope': scope, 'name': data_name, 'dataset': dataset, 'account': account, 'time': updated_at, 'rse': rse_name})

    # create report per rse
    for rse in data_per_rse.keys():
        fo = open(reports_dir + '/' + 'report_' + rse, 'w')
        for bad_file in data_per_rse[rse]:
            fo.write("%s %s %s %s\n" % (bad_file['scope'], bad_file['dataset'], bad_file['name'], bad_file['time']))

    # send report by mail
    for rse in data_per_rse.keys():
        rses.append(rse)

    fi.close()
    return rses


# the input
def get_bad_files(session, outfile=tmpdata_path):

    f = open(outfile, 'w')
    try:
        query = ''' select a.scope, a.name, b.scope, b.name, atlas_rucio.id2rse(a.rse_id), a.account, a.updated_at from atlas_rucio.bad_replicas a, atlas_rucio.contents_history b
 where a.state='L' and a.updated_at>sysdate-7 and b.did_type='D'and a.scope=b.child_scope and a.name=b.child_name '''

        result = session.execute(query)
        processed_files = []
        for row in result:
            if row[3].startswith('panda.'):
                continue
            if '_sub' in row[3]:
                continue
            f_did = row[0] + ':' + row[1]
            if f_did in processed_files:
                print 'double counted:', f_did
                continue
            else:
                processed_files.append(f_did)
            for col in row:
                f.write('%s ' % col)
            f.write('\n')

    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('get_bad_files\n')
        flog.write(str(e) + "\n")
        return False

    return True


def get_bad_files_from_dump(session):

    flog = open(log_path, 'a')
    url = 'https://rucio-hadoop.cern.ch/lost_files'
    dump7 = requests.get(url, verify=False)
    if dump7.status_code == 404:
        flog.write('ERROR: dump of bad files not reachable on hadoop')
        return False

    f = open(tmpdata_path, 'w')
    line_counter = 0
    processed_files = []
    for l in dump7.text.split('\n'):
        line_counter += 1
        data = l.split('\t')
        if len(data) < 7:
            flog.write('WARNING: line %i in dump does not contain full info \n' % line_counter)
            continue
        if data[3].startswith('panda.'):
            continue
        if '_sub' in data[3]:
            continue
        f_did = data[0] + ':' + data[1]
        if f_did in processed_files:
            print 'double counted:', f_did
            continue
        else:
            processed_files.append(f_did)
        updated_at = time.strftime('%Y-%m-%d', time.localtime(float(data[6])))
        f.write('%s %s %s %s %s %s %s\n' % (data[0], data[1], data[2], data[3], data[4], data[5], updated_at))
    flog.write('INFO: dump contains %i lines\n' % line_counter)

    return True


def main():

    # check folder hierarchy
    if not dirs_exist([base_dir, log_dir, tmp_dir, reports_dir], create_if_not_exist=create_dirs):
        sys.exit(CRITICAL)

    run_flag = run_judger(working_days)
    if not run_flag:
        sys.exit(OK)

    session = get_session()

    mails = {}
    # get input
    get_input = get_bad_files_from_dump(session)
    if not get_input:
        print 'WARNING: the dump is not accessible'
        get_input = get_bad_files(session)
        if not get_input:
            sys.exit(CRITICAL)
    elif force_rucio_select:
        print 'WARNING: forced rucio select flag is on, so call rucio'
        get_input = get_bad_files(session, outfile=tmpdata_path2)
        if not get_input:
            sys.exit(CRITICAL)

    # make and sent report to groups
    if groups:
        l_rses = report_by_rses(session)
        for rse in l_rses:
            reps = report_collector(rse, '', session)
            mails = merge_dicts(mails, reps)
    # make and sent report to users
    if users:
        l_acc = report_by_account(session)
        for acc in l_acc:
            reps = report_collector('', acc, session)
            mails = merge_dicts(mails, reps)
    if gdp:
        if test_mode:
            print "DEBUG: summary report to gdp"
        l_acc = report_gdp()
        for acc in l_acc:
            reps = report_collector('', acc, session)
            mails = merge_dicts(mails, reps)

    if len(list(set(mails.keys()))) != len(mails.keys()):
        print "ERROR: list of emails is not distinct"
        sys.exit('ERROR: list of emails is not distinct')

    if test_mode:
        send_report(tester_email, mails[tester_email])
        for m in mails.keys():
            flog = open(log_path, 'a')
            flog.write(m)
            flog.write(str(mails[m]))
            flog.write('\n')
    else:
        for m in mails.keys():
            send_report(m, mails[m])

    # clean tmp
    cmd = 'rm ' + tmpdata_path
    #os.system(cmd)

    sys.exit(OK)


if __name__ == '__main__':

    main()
