#!/usr/bin/env python
# Copyright European Organization for Nuclear Research (CERN) 2015
#
# Licensed under the Apache License, Version 2.0 (the "License");
# You may not use this file except in compliance with the License.
# You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
#
# Authors:
# - Tomas Javurek, Cedric Serfon, 2015
# - Alexander Bogdanchikov, 2019

import os
import sys
import smtplib
import time
import requests
import calendar
from email.mime.text import MIMEText
from email.MIMEMultipart import MIMEMultipart
from email.MIMEBase import MIMEBase
from email import Encoders
# from rucio.common.config import config_get
from datetime import datetime
from datetime import date
import pandas as pd

from rucio.db.sqla.session import get_session

# from rucio.core import monitor

# Exit statuses
OK, WARNING, CRITICAL, UNKNOWN = 0, 1, 2, 3

max_lines_inline = 20
users = True
groups = True
gdp = True

test_mode = True
test_mode_use_tmp_file = True  # for test_mode: if dump is not ready, try to use use tmp file instead of query rucio.
force_to_work_any_day = True  # if True and test_mode=True, force to run any day
force_rucio_select = False  # set it to True to force selection from rucio, even if rucio-hadoop request was successful
create_dirs = True

# tester_email = 'tomas.javurek@cern.ch'
tester_email = 'Alexander.Bogdanchikov@cern.ch'
# always_report_email = 'tomas.javurek@cern.ch'
always_report_email = 'Alexander.Bogdanchikov@cern.ch'
# gdp_emails = ['atlas-adc-dpa@cern.ch', 'tomas.javurek@cern.ch']
gdp_emails = ['agbogdan@cern.ch']
from_email = 'atlas-adc-ddm-support@cern.ch'

# run script on working_days only
working_days = ['Wednesday']

timestamp = datetime.today().strftime('%Y-%m-%d')
timestamp_long = datetime.today().strftime('%Y-%m-%d_%H-%M-%S')

# log_dir = '/var/log/rucio/lost_files/logs'
if not test_mode:
    base_dir = '/var/log/rucio/lost_files'
else:
    base_dir = '/afs/cern.ch/user/a/agbogdan/lost_files'  # + "-" + timestamp_long

log_dir = base_dir + '/logs'
tmp_dir = base_dir + '/tmp'
reports_dir = base_dir + '/reports'

if not test_mode:
    tmpdata_path = tmp_dir + '/rse-lost-files'
else:
    tmpdata_path = tmp_dir + '/rse-lost-files' + '-' + timestamp + '.txt'

tmpdata_path2 = tmp_dir + '/rse-lost-files-rucio-' + timestamp_long + '.txt'
tmpdata_path3 = tmp_dir + '/rse-lost-files-rucio-test-' + timestamp_long + '.txt'

log_path = log_dir + "/" + timestamp_long + '.log'


def print_time(method):
    def inner(*args, **kwargs):
        if not test_mode:  # do not count time when not in test mode
            return method(*args, **kwargs)
        arg_names = method.func_code.co_varnames[:method.func_code.co_argcount]
        method_args = ', '.join('%s=%r' % entry for entry in
                                zip(arg_names, args[:len(arg_names)]) + [("args", list(args[len(arg_names):]))] + [
                                    ("kwargs", kwargs)]) + ")"
        print '%s is up to start %r(%s)' % (datetime.now().strftime('%Y-%m-%d_%H-%M-%S'), method.__name__, method_args)
        tstart = time.time()
        result = method(*args, **kwargs)
        tend = time.time()
        print '%s finished in %.3f s: %r(%s)' % (
        datetime.now().strftime('%Y-%m-%d_%H-%M-%S'), tend - tstart, method.__name__, method_args)
        return result

    return inner


@print_time
def dirs_exist(dirs, create_if_not_exist=False):
    """
    checks the existence of directories and create them if not exist
    :param dirs: list of directories. Check starts from the beginning of the list
    :param create_if_not_exist: flag to create directories if not exists
    :return: True on success, False otherwise
    """
    for check_dir in dirs:
        if not os.path.isdir(check_dir):
            if os.path.exists(check_dir):
                if test_mode:
                    print ('DEBUG: failure: %s exists but not a directory ' % check_dir)
                return False
            if create_if_not_exist:
                try:
                    if test_mode:
                        print ('DEBUG: mkdir missed directory %s' % check_dir)
                    os.mkdir(check_dir, 0755)
                    continue
                except OSError as err:
                    if test_mode:
                        print ('DEBUG: failed to mkdir missed directory %s: %s' % (check_dir, err))
                    return False
            else:
                if test_mode:
                    print ('DEBUG: failure: directory %s is missed, flag create_if_not_existis is %s ' % (
                        check_dir, create_if_not_exist))
                return False
    return True


# protection against running this script every day
@print_time
def run_judger(run_days):
    """
    judge if the script has to run today according to run_days + allow run if force_to_work_day and test_mode flags are set
    :param run_days: list of days to run
    :return:  True if script can run
    """
    today = calendar.day_name[date.today().weekday()]
    flog = open(log_path, 'a')
    if today in run_days:
        flog.write('Today is %s.\n' % today)
        flog.write('I might try to work today.\n')
        return True
    else:
        flog.write('Today is %s. This is NOT my working day! I am working only on:\n' % today)
        flog.write("My run days are: " + str(run_days) + '\n')
        if test_mode and force_to_work_any_day:
            print (
                    ("INFO:  Normally I do not run on %s. My run days are %s. " +
                     "Now I run because test_mode and force_to_work_any_day flags are set\n") %
                    (today, str(run_days))
            )
            flog.write("The test_mode and force_to_work_any_day flags are set, I will run\n")
            return True
        return False


@print_time
def merge_dicts(d1, d2):
    dm = d1.copy()
    for a in d2.keys():
        if a not in dm.keys():
            dm[a] = d2[a]
        else:
            dm[a] = list(set(dm[a] + d2[a]))
    return dm


# extracting mails of users from Rucio DB
@print_time
def find_mails_users(account, session):
    mails = []
    try:
        query = ''' select distinct a.email from atlas_rucio.identities a, atlas_rucio.account_map b where
a.identity=b.identity and b.account='%s'  ''' % account
        print (datetime.today().strftime('%Y-%m-%d_%H-%M-%S') + " start exec query: " + query)
        result = session.execute(query)
        print (datetime.today().strftime('%Y-%m-%d_%H-%M-%S') + " end exec query")
        for row in result:
            for col in row:
                mails.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('find_mails_users\n')
        flog.write(str(e) + '\n')
        sys.exit(CRITICAL)
    if account == 'ddmadmin' or account == 'root':
        mails = ['atlas-adc-ddm-support@cern.ch']
    if always_report_email not in mails:
        mails.append(always_report_email)

    return mails


# hardcoded, TODO
@print_time
def find_mails_gdp():
    return gdp_emails


# extracting mails of physgroups from Rucio DB
@print_time
def find_mails_groups(rse, session):
    """
    :param rse:
    :param session:
    :return:
    """
    mails = []
    try:
        query = ''' select distinct email from atlas_rucio.identities where identity in
 (select identity from atlas_rucio.account_map where account in
 (select value from atlas_rucio.rse_attr_map where key = 'physgroup' and rse_id = atlas_rucio.rse2id('%s'))) ''' % rse
        print (datetime.today().strftime('%Y-%m-%d_%H-%M-%S') + " start exec query: " + query)
        result = session.execute(query)
        print (datetime.today().strftime('%Y-%m-%d_%H-%M-%S') + " end exec query")
        for row in result:
            for col in row:
                mails.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('find_mails_groups\n')
        flog.write(str(e) + '\n')
        sys.exit(CRITICAL)

    if always_report_email not in mails:
        mails.append(always_report_email)

    return mails


# find account for rule on given did
@print_time
def get_rule_owners(scope, name, session):
    rule_owners = []
    try:
        query = "select distinct(account) from atlas_rucio.rules where scope='%s' and name='%s'" % (scope, name)
        print (datetime.today().strftime('%Y-%m-%d_%H-%M-%S') + " start exec query: " + query)
        result = session.execute(query)
        print (datetime.today().strftime('%Y-%m-%d_%H-%M-%S') + " end exec query")
        for row in result:
            for col in row:
                rule_owners.append(str(col))
    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('get_rule_owners:')
        flog.write(str(e) + '\n')

    if test_mode:
        print 'DEBUG: ', scope, name
        print 'DEBUG: rule owners', rule_owners

    return rule_owners


# collects reports for given email
@print_time
def report_collector(rse, account, session):
    if test_mode:
        print ("DEBUG: report_collector was called with (%s, %s, %s)" % (rse, account, session))
    mails_reports = {}
    mail_list = []
    report_path = ''
    if groups and rse != '':
        mail_list = find_mails_groups(rse, session)
        report_path = reports_dir + '/' + 'report_' + rse
    if users and account != '' and account != 'gdp':
        mail_list = find_mails_users(account, session)
        report_path = reports_dir + '/' + 'report_' + account
    if gdp and account == 'gdp':
        mail_list = find_mails_gdp()
        report_path = reports_dir + '/' + 'report_' + account
    if mail_list == [] or report_path == '' or report_path == 'report_':
        return

    if test_mode:
        print ("DEBUG: report_collector created mail_list=%s" % mail_list)

    for mail in mail_list:
        if mail not in mails_reports:
            mails_reports[mail] = [report_path]
        else:
            mails_reports[mail].append(report_path)

    if test_mode:
        print ("DEBUG: report_collector created mail_reports=%s" % mails_reports)

    return mails_reports


# mailing agent
@print_time
def send_report(to_mail, report_paths):
    if test_mode:
        # print "DEBUG: mailing agent is accessed."
        print ("DEBUG: was called: send_report (to_mail=%s, report_paths=%s) " % (to_mail, ", ".join(report_paths)))

    # defining mailing list
    if test_mode:
        print 'DEBUG: notification would be send to:', to_mail
        recipients = [tester_email]
    else:
        recipients = [to_mail]

    msg = MIMEMultipart('alternative')
    msg['Subject'] = 'DDMops: completely lost files that may affect you - last 7 days'
    # note: from_mail will be specified in the smtplib.
    # msg['From'] = from_email
    msg['To'] = ", ".join(recipients)

    # always send the list, to avoid an empty message body
    # create body lines
    message_top = 'Please check the attached list of files that have been lost and can not be recovered. These files may affect you. In case of questions contact DDMops.\n'
    header = '<html><body>\n'
    footer = "</body></html>\n"
    lines = []
    lines_txt = []
    all_inline = True
    for report_path in report_paths:
        fr = open(report_path, 'r')
        for lost_file in fr.readlines():
            if len(lines) > max_lines_inline:
                all_inline = False
                break
            lines_txt.append(lost_file)
            # convert to html
            html_line = '<tr><td>' + lost_file.replace('\n', '').replace(' ', '</td><td>') + '</td></tr>\n'
            lines.append(html_line)
        fr.close()
        if not all_inline:
            break

    # for l in lines:
    #   msg.attach(MIMEText(str(l)))

    if all_inline:
        message_top += 'All lost files are presented in this inline list.\n'
    else:
        message_top += 'This list is NOT FULL,  all lost files info is in attachments.\n'
        lines_txt.append('...')
        lines.append('<tr>' + '<td>...</td>' * 4 + '</tr>')

    table_txt = ''.join(lines_txt)
    table = '<table cellspacing="0" cellpadding="0" border="1">\n' + ''.join(lines) + '</table>'
    msg.attach(MIMEText(message_top + table_txt, 'plain'))
    msg.attach(MIMEText(header + '<p>' + message_top + '</p>' + table + footer, 'html'))

    # attachments
    for report_path in report_paths:
        fr = open(report_path, 'rb')
        part = MIMEBase('text', 'plain')
        # part = MIMEBase('application', "octet-stream")
        part.set_payload(fr.read())
        Encoders.encode_base64(part)
        part.add_header('Content-Disposition', 'attachment; filename="%s"' % report_path)
        msg.attach(part)

    # sending email, s=server
    s = smtplib.SMTP('localhost')
    s.sendmail(from_email, recipients, msg.as_string())
    s.quit()

    flog = open(log_path, 'a')
    flog.write('Reports were sent to:\n')
    flog.write(str(recipients))
    if (recipients != [to_mail]):
        flog.write(" - for test, would be: " + to_mail)
    flog.write(str(report_paths))
    flog.write('\n\n')


# create report for gdp
# call mailing agent
@print_time
def report_gdp():
    # INIT
    if test_mode:
        print "DEBUG: making report for GDP"
        print "||||||||||||||||||||||||||||"
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)

    cmd = 'cp %s %s' % (tmpdata_path, reports_dir + '/' + 'report_gdp')
    os.system(cmd)

    return ['gdp']


@print_time
def report_by_account(session):
    """
     inspect lost file lines in in tmpdata_path, find account responsible for the lost file,
     build dictionary account -> lost_files_accoiunt
    :param session:
    :return:
    """
    # INIT
    if test_mode:
        print "DEBUG: making report by account"
        print "|||||||||||||||||||||||||||||||"
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)
    fi = open(tmpdata_path, 'r')
    data_per_account = {}
    accs = []

    # loop over lost files from get_bad_files()
    for line in fi.readlines():
        line = line.strip('\n')  # the line may have trailing new line if python treats file as txt (e.g. txt extension)
        scope = line.split(' ')[0]
        data_name = line.split(' ')[1]
        dataset = line.split(' ')[3]
        rse_name = line.split(' ')[4]
        account = line.split(' ')[5]
        updated_at = line.split(' ')[6]
        accounts = []

        # find owners of rule, they are contacted as well
        if test_mode:
            print "DEBUG: get rule owners"
        rule_owners = get_rule_owners(scope, dataset, session)
        # did_woners = get_did_owner TO BE DEVELOPED
        for own in rule_owners:
            if own not in accounts:
                accounts.append(own)
        if test_mode:
            print 'INFO:', rse_name, account, dataset, data_name
            if accounts == []:
                print "DEBUG: there is no account to be notified."
            else:
                print "DEBUG: rule owners found:", accounts
            print '======================='

        add_str = "%s %s %s %s" % (scope, dataset, data_name, updated_at)  # for some strange reason f
        for acc in accounts:
            if acc not in data_per_account.keys():
                data_per_account[acc] = []
            data_per_account[acc].append(add_str)
            # {'scope': scope, 'name': data_name, 'dataset': dataset, 'rse': rse_name, 'time': updated_at})

    if test_mode:
        print "DEBUG: creating reports and sending."

    # create report per account
    for account in data_per_account.keys():
        fo = open(reports_dir + '/' + 'report_' + account, 'w')
        for bad_file in data_per_account[account]:
            fo.write(bad_file)
            # fo.write("%s %s %s %s\n" % (bad_file['scope'], bad_file['dataset'], bad_file['name'], bad_file['time']))

    # send report by mail
    for account in data_per_account.keys():
        if test_mode:
            print "DEBUG: going to send the report."
        accs.append(account)

    if test_mode:
        if data_per_account == {}:
            print "DEBUG: nothing to send."

    if test_mode:
        print "DEBUG: report by accounts done."
    fi.close()
    return accs


# make report for each rse
# call the mailing agent
@print_time
def report_by_rses(session):
    rses = []
    # INIT
    if not os.path.isfile(tmpdata_path):
        print "ERROR: lost files not downloaded"
        sys.exit(CRITICAL)
    fi = open(tmpdata_path, 'r')
    data_per_rse = {}

    # loop over lost files from get_bad_files()
    for line in fi.readlines():
        line = line.strip('\n')  # the line may have trailing new line if python treats file as txt (e.g. txt extension)
        scope = line.split(' ')[0]
        data_name = line.split(' ')[1]
        dataset = line.split(' ')[3]
        rse_name = line.split(' ')[4]
        account = line.split(' ')[5]
        updated_at = line.split(' ')[6]

        if rse_name not in data_per_rse.keys():
            data_per_rse[rse_name] = [
                {'scope': scope, 'name': data_name, 'dataset': dataset, 'account': account, 'time': updated_at,
                 'rse': rse_name}]
        else:
            data_per_rse[rse_name].append(
                {'scope': scope, 'name': data_name, 'dataset': dataset, 'account': account, 'time': updated_at,
                 'rse': rse_name})

    # create report per rse
    for rse in data_per_rse.keys():
        fo = open(reports_dir + '/' + 'report_' + rse, 'w')
        for bad_file in data_per_rse[rse]:
            fo.write("%s %s %s %s\n" % (bad_file['scope'], bad_file['dataset'], bad_file['name'], bad_file['time']))

    # send report by mail
    for rse in data_per_rse.keys():
        rses.append(rse)

    fi.close()
    return rses


# the input
@print_time
def get_bad_files(session, outfile=tmpdata_path, orig_query=True):
    if test_mode and test_mode_use_tmp_file and os.path.isfile(tmpdata_path) and os.stat(tmpdata_path).st_size > 0:
        print(
                    'the flags "test_mode" and "test_mode_use_tmp_file" are set: do not query rucio, use tmp file "%s" instead' % tmpdata_path)
        return True
    f = open(outfile, 'w')
    try:
        if orig_query:
            query = ''' select a.scope, a.name, b.scope, b.name, atlas_rucio.id2rse(a.rse_id), a.account, a.updated_at from atlas_rucio.bad_replicas a, atlas_rucio.contents_history b
    where a.state='L' and a.updated_at>sysdate-7 and b.did_type='D' and a.scope=b.child_scope and a.name=b.child_name '''
        else:
            query0 = (  # origin, just reformatted in multiple lines
                "select a.scope, a.name, b.scope, b.name, atlas_rucio.id2rse(a.rse_id), a.account, a.updated_at from atlas_rucio.bad_replicas a, atlas_rucio.contents_history b"
                " where a.state='L' and a.updated_at>sysdate-7 and b.did_type='D' and a.scope=b.child_scope and a.name=b.child_name "
                " and  b.name not like 'panda.%' and b.name not like '%_sub%' "
            )
            query1 = (  # nested select to remove unwanted lines
                "select * from"
                " ( select a.scope as scope, a.name as name, b.scope as bscope,  b.name as dataset, atlas_rucio.id2rse(a.rse_id) as rse, a.account as account, a.updated_at as upd"
                " from atlas_rucio.bad_replicas a, atlas_rucio.contents_history b"
                " where a.state='L' and a.updated_at>sysdate-7 and b.did_type='D' and a.scope=b.child_scope and a.name=b.child_name )  T"  # mysql "as T" does not work for Oracle
                " where T.dataset not like 'panda.%' and T.dataset not like '%_sub%' "
            )
            query2 = (  # query1 + nested select bad_replicas in last 7 days first
                "select * from"
                " ( select a.scope as scope, a.name as name, b.scope as bscope,  b.name as dataset, atlas_rucio.id2rse(a.rse_id) as rse, a.account as account, a.updated_at as upd"
                " from (select scope, name, rse_id, account, updated_at from atlas_rucio.bad_replicas  where updated_at>sysdate-7) a,"  # at first limit selection to the interval
                " atlas_rucio.contents_history b"
                " where a.state='L' and  b.did_type='D' and a.scope=b.child_scope and a.name=b.child_name )  T"  # mysql "as T" does not work for Oracle
                " where T.dataset not like 'panda.%' and T.dataset not like '%_sub%' "
            )
            query3 = (  # query1 + nested select conditions on bad_repilicas table first
                "select * from"
                " ( select a.scope as scope, a.name as name, b.scope as bscope,  b.name as dataset, atlas_rucio.id2rse(a.rse_id) as rse, a.account as account, a.updated_at as upd"
                " from (select scope, name, rse_id, account, updated_at from atlas_rucio.bad_replicas  where updated_at>sysdate-7 and state='L' ) a,"  # at first limit selection to the interval
                " atlas_rucio.contents_history b"
                " where b.did_type='D' and a.scope=b.child_scope and a.name=b.child_name )  T"  # mysql "as T" does not work for Oracle
                " where T.dataset not like 'panda.%' and T.dataset not like '%_sub%' "
            )
            query = query1

        print (datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + " start exec query: " + query)
        result = session.execute(query)
        print (datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + " end exec query")
        processed_files = []
        processed_files_full = []
        for row in result:
            if row[3].startswith('panda.'):
                continue
            if '_sub' in row[3]:
                continue

            f_did_full = row[0] + ':' + row[1] + ':' + row[4]
            if f_did_full in processed_files_full:
                unique_file = False
            else:
                unique_file = True
                processed_files_full.append(f_did_full)

            f_did = row[0] + ':' + row[1]
            if f_did in processed_files:
                print 'double counted:', f_did
                if unique_file:
                    print "The bug! The file is unique: " + f_did_full
                continue
            else:
                processed_files.append(f_did)
            # for col in row:
            #    f.write('%s ' % col)
            # f.write('\n')

            # shorter and does not add a trailing space (not nice + dump results are stored without the trailing spaces)
            # str() conversion is necessary, as row[6] has datetime type
            f.write(' '.join(str(x) for x in row) + '\n')

    except Exception, e:
        flog = open(log_path, 'a')
        flog.write('get_bad_files\n')
        flog.write(str(e) + "\n")
        return False

    return True


@print_time
def get_bad_files_from_dump(session):
    flog = open(log_path, 'a')
    url = 'https://rucio-hadoop.cern.ch/lost_files'
    dump7 = requests.get(url, verify=False)
    if dump7.status_code == 404:
        flog.write('ERROR: dump of bad files not reachable on hadoop\n')
        return False

    f = open(tmpdata_path, 'w')
    line_counter = 0
    processed_files = []
    processed_files_full = []
    for l in dump7.text.split('\n'):
        line_counter += 1
        data = l.split('\t')
        if len(data) < 7:
            flog.write('WARNING: line %i in dump does not contain full info \n' % line_counter)
            continue
        if data[3].startswith('panda.'):
            continue
        if '_sub' in data[3]:
            continue

        # check the full file id (with RSE) uniqueness
        f_did_full = data[0] + ':' + data[1] + ':' + data[4]
        if f_did_full in processed_files_full:
            unique_file = False
        else:
            unique_file = True
            processed_files_full.append(f_did_full)

        f_did = data[0] + ':' + data[1]
        if f_did in processed_files:
            print 'double counted:', f_did
            if unique_file:
                print "The file is unique: " + f_did_full
            continue
        else:
            processed_files.append(f_did)
        updated_at = time.strftime('%Y-%m-%d', time.localtime(float(data[6])))
        f.write('%s %s %s %s %s %s %s\n' % (data[0], data[1], data[2], data[3], data[4], data[5], updated_at))
    flog.write('INFO: dump contains %i lines\n' % line_counter)

    return True


@print_time
def main():
    # check folder hierarchy
    if not dirs_exist([base_dir, log_dir, tmp_dir, reports_dir], create_if_not_exist=create_dirs):
        sys.exit(CRITICAL)

    run_flag = run_judger(working_days)
    if not run_flag:
        sys.exit(OK)

    session = get_session()

    mails = {}
    # get input
    get_input = get_bad_files_from_dump(session)
    if not get_input:
        print 'WARNING: the dump is not accessible'
        get_input = get_bad_files(session)
        if not get_input:
            sys.exit(CRITICAL)
    elif force_rucio_select:
        print 'WARNING: forced rucio select flag is on, so call rucio'
        # get_input = get_bad_files(session, outfile=tmpdata_path2)
        # if not get_input:
        #    sys.exit(CRITICAL)
        get_input = get_bad_files(session, outfile=tmpdata_path3, orig_query=False)
        if not get_input:
            sys.exit(CRITICAL)

    # make and sent report to groups
    if groups:
        l_rses = report_by_rses(session)
        for rse in l_rses:
            reps = report_collector(rse, '', session)
            mails = merge_dicts(mails, reps)
    # make and sent report to users
    if users:
        l_acc = report_by_account(session)
        for acc in l_acc:
            reps = report_collector('', acc, session)
            mails = merge_dicts(mails, reps)
    if gdp:
        if test_mode:
            print "DEBUG: summary report to gdp"
        l_acc = report_gdp()
        for acc in l_acc:
            reps = report_collector('', acc, session)
            mails = merge_dicts(mails, reps)

    if len(list(set(mails.keys()))) != len(mails.keys()):
        print "ERROR: list of emails is not distinct"
        sys.exit('ERROR: list of emails is not distinct')

    if test_mode:
        send_report(tester_email, mails[tester_email])
        flog = open(log_path, 'a')
        flog.write("This script is running in test_mode, the next reports are prepared, but not sent:\n")
        for m in mails.keys():
            flog.write(m)
            flog.write(str(mails[m]))
            flog.write('\n')
    else:
        for m in mails.keys():
            send_report(m, mails[m])

    # clean tmp
    cmd = 'rm ' + tmpdata_path
    # os.system(cmd)


if __name__ == '__main__':
    main()
    sys.exit(OK)
